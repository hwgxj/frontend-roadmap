# ğŸŒŠ å®ç°æµå¼è¾“å‡ºï¼ˆæ‰“å­—æœºæ•ˆæœï¼‰

è®©AIåƒæˆ‘ä¸€æ ·é€å­—è¾“å‡ºï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§æ˜¾ç¤ºå®Œæ•´ç­”æ¡ˆã€‚

---

## ğŸ“Š å¯¹æ¯”

### å½“å‰ï¼ˆéæµå¼ï¼‰
```
[ ç”¨æˆ· ] ä½ å¥½
[ AI   ] æ€è€ƒä¸­...æ€è€ƒä¸­...æ€è€ƒä¸­...
         ï¼ˆç­‰å¾…10ç§’ï¼‰
[ AI   ] ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´... ï¼ˆä¸€æ¬¡æ€§å‡ºç°ï¼‰
```

### æµå¼è¾“å‡º
```
[ ç”¨æˆ· ] ä½ å¥½
[ AI   ] ä½ 
[ AI   ] å¥½
[ AI   ] ï¼
[ AI   ] æˆ‘
[ AI   ] æ˜¯
[ AI   ] AI
[ AI   ] åŠ©
[ AI   ] æ‰‹... ï¼ˆåƒæ‰“å­—ä¸€æ ·é€å­—å‡ºç°ï¼‰
```

---

## ğŸ¯ å®ç°æ–¹å¼

### æ–¹æ¡ˆå–å†³äºä½ ä½¿ç”¨çš„AIæœåŠ¡

#### å¦‚æœä½¿ç”¨ OpenAI API

**åç«¯æ”¹é€ **ï¼š
```typescript
// src/app/api/ai-chat/route.ts
import { OpenAIStream, StreamingTextResponse } from 'ai';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(req: Request) {
  const { messages } = await req.json();

  // âœ… å¼€å¯ stream: true
  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    stream: true,  // â† å…³é”®ï¼šå¼€å¯æµå¼è¾“å‡º
    messages,
  });

  // è½¬æ¢ä¸ºæµå¼å“åº”
  const stream = OpenAIStream(response);
  return new StreamingTextResponse(stream);
}
```

**å‰ç«¯æ¥æ”¶**ï¼š
```typescript
// å‰ç«¯ç»„ä»¶
const [message, setMessage] = useState('');
const [isStreaming, setIsStreaming] = useState(false);

const sendMessage = async (userMessage: string) => {
  setIsStreaming(true);
  setMessage(''); // æ¸…ç©º

  const response = await fetch('/api/ai-chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      messages: [{ role: 'user', content: userMessage }]
    }),
  });

  // âœ… è¯»å–æµå¼æ•°æ®
  const reader = response.body?.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    setMessage(prev => prev + chunk); // é€æ­¥æ‹¼æ¥
  }

  setIsStreaming(false);
};
```

---

#### å¦‚æœä½¿ç”¨ Vercel AI SDKï¼ˆæ¨èï¼‰

**å®‰è£…**ï¼š
```bash
npm install ai
```

**åç«¯**ï¼š
```typescript
// src/app/api/ai-chat/route.ts
import { OpenAIStream, StreamingTextResponse } from 'ai';
import { Configuration, OpenAIApi } from 'openai-edge';

const config = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(config);

export const runtime = 'edge'; // ä½¿ç”¨ Edge Runtime

export async function POST(req: Request) {
  const { messages } = await req.json();

  const response = await openai.createChatCompletion({
    model: 'gpt-4',
    stream: true,
    messages,
  });

  const stream = OpenAIStream(response);
  return new StreamingTextResponse(stream);
}
```

**å‰ç«¯**ï¼ˆè¶…ç®€å•ï¼‰ï¼š
```typescript
'use client';

import { useChat } from 'ai/react';

export default function Chat() {
  const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat({
    api: '/api/ai-chat',
  });

  return (
    <div>
      {/* æ˜¾ç¤ºæ¶ˆæ¯ */}
      {messages.map(m => (
        <div key={m.id}>
          <strong>{m.role}: </strong>
          {m.content} {/* âœ… è‡ªåŠ¨æµå¼æ˜¾ç¤º */}
        </div>
      ))}

      {/* è¾“å…¥æ¡† */}
      <form onSubmit={handleSubmit}>
        <input
          value={input}
          onChange={handleInputChange}
          placeholder="è¾“å…¥æ¶ˆæ¯..."
        />
        <button type="submit">å‘é€</button>
      </form>
    </div>
  );
}
```

---

#### å¦‚æœä½¿ç”¨è‡ªå®šä¹‰AIæˆ–å…¶ä»–æœåŠ¡

**åç«¯æ‰‹åŠ¨å®ç°æµå¼**ï¼š
```typescript
// src/app/api/ai-chat/route.ts
export async function POST(req: Request) {
  const { message } = await req.json();

  // åˆ›å»ºå¯è¯»æµ
  const encoder = new TextEncoder();
  const stream = new ReadableStream({
    async start(controller) {
      // æ¨¡æ‹ŸAIé€å­—è¿”å›
      const response = await callYourAI(message);
      
      // é€å­—å‘é€
      for (const char of response) {
        controller.enqueue(encoder.encode(char));
        await sleep(20); // æ¯20mså‘é€ä¸€ä¸ªå­—
      }
      
      controller.close();
    },
  });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'Transfer-Encoding': 'chunked',
    },
  });
}
```

**å‰ç«¯æ¥æ”¶**ï¼š
```typescript
const sendMessage = async (text: string) => {
  setMessage('');
  
  const response = await fetch('/api/ai-chat', {
    method: 'POST',
    body: JSON.stringify({ message: text }),
  });

  const reader = response.body?.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value, { stream: true });
    setMessage(prev => prev + chunk);
  }
};
```

---

## ğŸ¨ å®Œæ•´ç¤ºä¾‹ç»„ä»¶

```typescript
'use client';

import { useState, useRef, useEffect } from 'react';

export default function StreamingChat() {
  const [messages, setMessages] = useState<Array<{role: string, content: string}>>([]);
  const [input, setInput] = useState('');
  const [isStreaming, setIsStreaming] = useState(false);
  const [currentStream, setCurrentStream] = useState('');
  const messagesEndRef = useRef<HTMLDivElement>(null);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, currentStream]);

  const sendMessage = async () => {
    if (!input.trim() || isStreaming) return;

    const userMessage = input;
    setInput('');
    setMessages(prev => [...prev, { role: 'user', content: userMessage }]);

    setIsStreaming(true);
    setCurrentStream('');

    try {
      const response = await fetch('/api/ai-chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          messages: [...messages, { role: 'user', content: userMessage }]
        }),
      });

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      let fullResponse = '';

      while (true) {
        const { done, value } = await reader!.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        fullResponse += chunk;
        setCurrentStream(fullResponse); // å®æ—¶æ›´æ–°
      }

      // å®Œæˆåæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
      setMessages(prev => [...prev, { role: 'assistant', content: fullResponse }]);
      setCurrentStream('');
    } catch (error) {
      console.error('æµå¼è¾“å‡ºé”™è¯¯:', error);
    } finally {
      setIsStreaming(false);
    }
  };

  return (
    <div className="flex flex-col h-screen max-w-3xl mx-auto p-4">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="flex-1 overflow-y-auto space-y-4 mb-4">
        {messages.map((msg, idx) => (
          <div
            key={idx}
            className={`p-4 rounded-lg ${
              msg.role === 'user'
                ? 'bg-blue-100 ml-12'
                : 'bg-gray-100 mr-12'
            }`}
          >
            <div className="font-bold mb-1">
              {msg.role === 'user' ? 'ğŸ‘¤ ä½ ' : 'ğŸ¤– AI'}
            </div>
            <div className="whitespace-pre-wrap">{msg.content}</div>
          </div>
        ))}

        {/* æ­£åœ¨æµå¼è¾“å‡ºçš„æ¶ˆæ¯ */}
        {isStreaming && currentStream && (
          <div className="p-4 rounded-lg bg-gray-100 mr-12">
            <div className="font-bold mb-1">ğŸ¤– AI</div>
            <div className="whitespace-pre-wrap">
              {currentStream}
              <span className="animate-pulse">â–Š</span> {/* å…‰æ ‡ */}
            </div>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* è¾“å…¥æ¡† */}
      <div className="flex gap-2">
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="è¾“å…¥æ¶ˆæ¯..."
          disabled={isStreaming}
          className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
        />
        <button
          onClick={sendMessage}
          disabled={isStreaming || !input.trim()}
          className="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 transition-colors"
        >
          {isStreaming ? 'ç”Ÿæˆä¸­...' : 'å‘é€'}
        </button>
      </div>
    </div>
  );
}
```

---

## ğŸ¯ å…³é”®ç‚¹

### 1. åç«¯å¿…é¡»æ”¯æŒæµå¼è¾“å‡º
```typescript
// âœ… æ­£ç¡®ï¼šä½¿ç”¨æµå¼API
stream: true

// âŒ é”™è¯¯ï¼šç­‰å¾…å®Œæ•´å“åº”
await getFullResponse()
```

### 2. å‰ç«¯ä½¿ç”¨ ReadableStream
```typescript
const reader = response.body.getReader();
while (true) {
  const { done, value } = await reader.read();
  // æ¯æ”¶åˆ°ä¸€å—æ•°æ®å°±ç«‹å³æ˜¾ç¤º
}
```

### 3. å®æ—¶æ›´æ–°UI
```typescript
setMessage(prev => prev + chunk); // æ‹¼æ¥æ–°å†…å®¹
```

---

## ğŸš€ å¿«é€Ÿå®ç°æ­¥éª¤

### 1. å®‰è£…ä¾èµ–
```bash
npm install ai openai-edge
```

### 2. é…ç½®ç¯å¢ƒå˜é‡
```bash
# .env.local
OPENAI_API_KEY=your_api_key_here
```

### 3. åˆ›å»ºæµå¼API
```
src/app/api/ai-chat/route.ts ï¼ˆä½¿ç”¨ä¸Šé¢çš„ä»£ç ï¼‰
```

### 4. ä½¿ç”¨ useChat Hook
```typescript
import { useChat } from 'ai/react';
const { messages } = useChat(); // è‡ªåŠ¨å¤„ç†æµå¼
```

---

## ğŸ­ æ•ˆæœå¯¹æ¯”

### éæµå¼ï¼ˆå½“å‰ï¼‰
- â° ç­‰å¾…æ—¶é—´ï¼š10ç§’çœ‹ä¸åˆ°ä»»ä½•è¾“å‡º
- ğŸ˜° ç”¨æˆ·ä½“éªŒï¼šç„¦è™‘ï¼Œä¸çŸ¥é“AIåœ¨å¹²å˜›
- ğŸ’” ä½“éªŒå·®

### æµå¼ï¼ˆæ”¹è¿›åï¼‰
- âš¡ ç«‹å³å“åº”ï¼š0.5ç§’å¼€å§‹çœ‹åˆ°è¾“å‡º
- ğŸ˜Š ç”¨æˆ·ä½“éªŒï¼šæœ‰åé¦ˆï¼ŒçŸ¥é“AIåœ¨å·¥ä½œ
- â¤ï¸ ä½“éªŒå¥½ï¼ˆåƒæˆ‘è¿™æ ·ï¼‰

---

## ğŸ“š æ¨èæ–¹æ¡ˆ

**æœ€ç®€å•**: Vercel AI SDK + useChat
**æœ€çµæ´»**: æ‰‹åŠ¨å®ç° ReadableStream
**æœ€å¼ºå¤§**: OpenAI SDK + Streaming

---

éœ€è¦æˆ‘å¸®ä½ å®ç°å…·ä½“çš„æµå¼èŠå¤©åŠŸèƒ½å—ï¼Ÿå‘Šè¯‰æˆ‘ï¼š
1. ä½ ç”¨çš„æ˜¯ä»€ä¹ˆAIæœåŠ¡ï¼Ÿï¼ˆOpenAI / Claude / è‡ªå»ºï¼‰
2. æƒ³å®ç°åœ¨å“ªä¸ªé¡µé¢ï¼Ÿ
3. å·²æœ‰çš„AIå¯¹è¯ä»£ç åœ¨å“ªé‡Œï¼Ÿ

æˆ‘å¯ä»¥å¸®ä½ ç›´æ¥æ”¹é€ ï¼ğŸš€


